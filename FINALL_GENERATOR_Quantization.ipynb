{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614b1699-bfca-4763-b531-f4d49a7c3a17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install https://github.com/casper-hansen/AutoAWQ/releases/download/v0.1.6/autoawq-0.1.6+cu118-cp310-cp310-linux_x86_64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9959a6f2-323c-4a8f-b00f-16257ea4e898",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: einops in /opt/conda/lib/python3.10/site-packages (0.7.0)\n",
      "Requirement already satisfied: autoawq==0.1.7 in /opt/conda/lib/python3.10/site-packages (0.1.7+cu118)\n",
      "Requirement already satisfied: torch>=2.0.1 in /opt/conda/lib/python3.10/site-packages (from autoawq==0.1.7) (2.1.0)\n",
      "Collecting transformers>=4.35.0 (from autoawq==0.1.7)\n",
      "  Obtaining dependency information for transformers>=4.35.0 from https://files.pythonhosted.org/packages/12/dd/f17b11a93a9ca27728e12512d167eb1281c151c4c6881d3ab59eb58f4127/transformers-4.35.2-py3-none-any.whl.metadata\n",
      "  Using cached transformers-4.35.2-py3-none-any.whl.metadata (123 kB)\n",
      "Requirement already satisfied: tokenizers>=0.12.1 in /opt/conda/lib/python3.10/site-packages (from autoawq==0.1.7) (0.14.1)\n",
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (from autoawq==0.1.7) (0.24.0)\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from autoawq==0.1.7) (0.1.99)\n",
      "Requirement already satisfied: lm-eval in /opt/conda/lib/python3.10/site-packages (from autoawq==0.1.7) (0.3.0)\n",
      "Requirement already satisfied: texttable in /opt/conda/lib/python3.10/site-packages (from autoawq==0.1.7) (1.7.0)\n",
      "Requirement already satisfied: toml in /opt/conda/lib/python3.10/site-packages (from autoawq==0.1.7) (0.10.2)\n",
      "Requirement already satisfied: attributedict in /opt/conda/lib/python3.10/site-packages (from autoawq==0.1.7) (0.3.0)\n",
      "Requirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from autoawq==0.1.7) (4.25.1)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from autoawq==0.1.7) (0.16.0)\n",
      "Requirement already satisfied: tabulate in /opt/conda/lib/python3.10/site-packages (from autoawq==0.1.7) (0.9.0)\n",
      "Requirement already satisfied: huggingface_hub<0.18,>=0.16.4 in /opt/conda/lib/python3.10/site-packages (from tokenizers>=0.12.1->autoawq==0.1.7) (0.17.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.1->autoawq==0.1.7) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.1->autoawq==0.1.7) (4.7.1)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.1->autoawq==0.1.7) (1.11.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.1->autoawq==0.1.7) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.1->autoawq==0.1.7) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.1->autoawq==0.1.7) (2023.9.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.35.0->autoawq==0.1.7) (1.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.35.0->autoawq==0.1.7) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.35.0->autoawq==0.1.7) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.35.0->autoawq==0.1.7) (2023.10.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers>=4.35.0->autoawq==0.1.7) (2.31.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.35.0->autoawq==0.1.7) (0.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.35.0->autoawq==0.1.7) (4.65.0)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate->autoawq==0.1.7) (5.9.0)\n",
      "Requirement already satisfied: rootpath>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from attributedict->autoawq==0.1.7) (0.1.1)\n",
      "Requirement already satisfied: inspecta>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from attributedict->autoawq==0.1.7) (0.1.3)\n",
      "Requirement already satisfied: colour-runner>=0.0.5 in /opt/conda/lib/python3.10/site-packages (from attributedict->autoawq==0.1.7) (0.1.1)\n",
      "Requirement already satisfied: deepdiff>=3.3.0 in /opt/conda/lib/python3.10/site-packages (from attributedict->autoawq==0.1.7) (6.7.1)\n",
      "Requirement already satisfied: tox>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from attributedict->autoawq==0.1.7) (4.11.4)\n",
      "Requirement already satisfied: coverage>=4.5.2 in /opt/conda/lib/python3.10/site-packages (from attributedict->autoawq==0.1.7) (7.3.2)\n",
      "Requirement already satisfied: codecov>=2.0.15 in /opt/conda/lib/python3.10/site-packages (from attributedict->autoawq==0.1.7) (2.1.13)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from lm-eval->autoawq==0.1.7) (2.14.7)\n",
      "Requirement already satisfied: jsonlines in /opt/conda/lib/python3.10/site-packages (from lm-eval->autoawq==0.1.7) (4.0.0)\n",
      "Requirement already satisfied: numexpr in /opt/conda/lib/python3.10/site-packages (from lm-eval->autoawq==0.1.7) (2.8.7)\n",
      "Requirement already satisfied: openai>=0.6.4 in /opt/conda/lib/python3.10/site-packages (from lm-eval->autoawq==0.1.7) (1.3.6)\n",
      "Requirement already satisfied: pybind11>=2.6.2 in /opt/conda/lib/python3.10/site-packages (from lm-eval->autoawq==0.1.7) (2.11.1)\n",
      "Requirement already satisfied: pycountry in /opt/conda/lib/python3.10/site-packages (from lm-eval->autoawq==0.1.7) (22.3.5)\n",
      "Requirement already satisfied: pytablewriter in /opt/conda/lib/python3.10/site-packages (from lm-eval->autoawq==0.1.7) (1.2.0)\n",
      "Requirement already satisfied: rouge-score>=0.0.4 in /opt/conda/lib/python3.10/site-packages (from lm-eval->autoawq==0.1.7) (0.1.2)\n",
      "Requirement already satisfied: sacrebleu==1.5.0 in /opt/conda/lib/python3.10/site-packages (from lm-eval->autoawq==0.1.7) (1.5.0)\n",
      "Requirement already satisfied: scikit-learn>=0.24.1 in /opt/conda/lib/python3.10/site-packages (from lm-eval->autoawq==0.1.7) (1.3.2)\n",
      "Requirement already satisfied: sqlitedict in /opt/conda/lib/python3.10/site-packages (from lm-eval->autoawq==0.1.7) (2.1.0)\n",
      "Requirement already satisfied: tqdm-multiprocess in /opt/conda/lib/python3.10/site-packages (from lm-eval->autoawq==0.1.7) (0.0.11)\n",
      "Requirement already satisfied: zstandard in /opt/conda/lib/python3.10/site-packages (from lm-eval->autoawq==0.1.7) (0.19.0)\n",
      "Requirement already satisfied: portalocker in /opt/conda/lib/python3.10/site-packages (from sacrebleu==1.5.0->lm-eval->autoawq==0.1.7) (2.8.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->autoawq==0.1.7) (10.0.1)\n",
      "Requirement already satisfied: blessings in /opt/conda/lib/python3.10/site-packages (from colour-runner>=0.0.5->attributedict->autoawq==0.1.7) (1.7)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.10/site-packages (from colour-runner>=0.0.5->attributedict->autoawq==0.1.7) (2.15.1)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->lm-eval->autoawq==0.1.7) (14.0.1)\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->lm-eval->autoawq==0.1.7) (0.6)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->lm-eval->autoawq==0.1.7) (0.3.7)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->lm-eval->autoawq==0.1.7) (2.1.2)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->lm-eval->autoawq==0.1.7) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->lm-eval->autoawq==0.1.7) (0.70.15)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->lm-eval->autoawq==0.1.7) (3.9.1)\n",
      "Requirement already satisfied: ordered-set<4.2.0,>=4.0.2 in /opt/conda/lib/python3.10/site-packages (from deepdiff>=3.3.0->attributedict->autoawq==0.1.7) (4.1.0)\n",
      "Requirement already satisfied: six>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from inspecta>=0.1.0->attributedict->autoawq==0.1.7) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from inspecta>=0.1.0->attributedict->autoawq==0.1.7) (2.3.0)\n",
      "Requirement already satisfied: anyio<4,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from openai>=0.6.4->lm-eval->autoawq==0.1.7) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from openai>=0.6.4->lm-eval->autoawq==0.1.7) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from openai>=0.6.4->lm-eval->autoawq==0.1.7) (0.25.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from openai>=0.6.4->lm-eval->autoawq==0.1.7) (2.4.2)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from openai>=0.6.4->lm-eval->autoawq==0.1.7) (1.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.35.0->autoawq==0.1.7) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.35.0->autoawq==0.1.7) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.35.0->autoawq==0.1.7) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.35.0->autoawq==0.1.7) (2023.7.22)\n",
      "Requirement already satisfied: coloredlogs>=10.0 in /opt/conda/lib/python3.10/site-packages (from rootpath>=0.1.0->attributedict->autoawq==0.1.7) (15.0.1)\n",
      "Requirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge-score>=0.0.4->lm-eval->autoawq==0.1.7) (2.0.0)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge-score>=0.0.4->lm-eval->autoawq==0.1.7) (3.8.1)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.24.1->lm-eval->autoawq==0.1.7) (1.11.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.24.1->lm-eval->autoawq==0.1.7) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.24.1->lm-eval->autoawq==0.1.7) (3.2.0)\n",
      "Requirement already satisfied: cachetools>=5.3.1 in /opt/conda/lib/python3.10/site-packages (from tox>=3.0.0->attributedict->autoawq==0.1.7) (5.3.2)\n",
      "Requirement already satisfied: chardet>=5.2 in /opt/conda/lib/python3.10/site-packages (from tox>=3.0.0->attributedict->autoawq==0.1.7) (5.2.0)\n",
      "Requirement already satisfied: colorama>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from tox>=3.0.0->attributedict->autoawq==0.1.7) (0.4.6)\n",
      "Requirement already satisfied: platformdirs>=3.10 in /opt/conda/lib/python3.10/site-packages (from tox>=3.0.0->attributedict->autoawq==0.1.7) (3.11.0)\n",
      "Requirement already satisfied: pluggy>=1.3 in /opt/conda/lib/python3.10/site-packages (from tox>=3.0.0->attributedict->autoawq==0.1.7) (1.3.0)\n",
      "Requirement already satisfied: pyproject-api>=1.6.1 in /opt/conda/lib/python3.10/site-packages (from tox>=3.0.0->attributedict->autoawq==0.1.7) (1.6.1)\n",
      "Requirement already satisfied: tomli>=2.0.1 in /opt/conda/lib/python3.10/site-packages (from tox>=3.0.0->attributedict->autoawq==0.1.7) (2.0.1)\n",
      "Requirement already satisfied: virtualenv>=20.24.3 in /opt/conda/lib/python3.10/site-packages (from tox>=3.0.0->attributedict->autoawq==0.1.7) (20.24.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=2.0.1->autoawq==0.1.7) (2.1.1)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonlines->lm-eval->autoawq==0.1.7) (23.1.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from pycountry->lm-eval->autoawq==0.1.7) (68.0.0)\n",
      "Requirement already satisfied: DataProperty<2,>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from pytablewriter->lm-eval->autoawq==0.1.7) (1.0.1)\n",
      "Requirement already satisfied: mbstrdecoder<2,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from pytablewriter->lm-eval->autoawq==0.1.7) (1.1.3)\n",
      "Requirement already satisfied: pathvalidate<4,>=2.3.0 in /opt/conda/lib/python3.10/site-packages (from pytablewriter->lm-eval->autoawq==0.1.7) (3.2.0)\n",
      "Requirement already satisfied: tabledata<2,>=1.3.1 in /opt/conda/lib/python3.10/site-packages (from pytablewriter->lm-eval->autoawq==0.1.7) (1.3.3)\n",
      "Requirement already satisfied: tcolorpy<1,>=0.0.5 in /opt/conda/lib/python3.10/site-packages (from pytablewriter->lm-eval->autoawq==0.1.7) (0.1.4)\n",
      "Requirement already satisfied: typepy[datetime]<2,>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from pytablewriter->lm-eval->autoawq==0.1.7) (1.3.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=2.0.1->autoawq==0.1.7) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from anyio<4,>=3.5.0->openai>=0.6.4->lm-eval->autoawq==0.1.7) (1.0.4)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /opt/conda/lib/python3.10/site-packages (from coloredlogs>=10.0->rootpath>=0.1.0->attributedict->autoawq==0.1.7) (10.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->lm-eval->autoawq==0.1.7) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->lm-eval->autoawq==0.1.7) (1.9.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->lm-eval->autoawq==0.1.7) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->lm-eval->autoawq==0.1.7) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->lm-eval->autoawq==0.1.7) (4.0.3)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai>=0.6.4->lm-eval->autoawq==0.1.7) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=0.6.4->lm-eval->autoawq==0.1.7) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai>=0.6.4->lm-eval->autoawq==0.1.7) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai>=0.6.4->lm-eval->autoawq==0.1.7) (2.10.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.0 in /opt/conda/lib/python3.10/site-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm-eval->autoawq==0.1.7) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2018.9 in /opt/conda/lib/python3.10/site-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm-eval->autoawq==0.1.7) (2023.3.post1)\n",
      "Requirement already satisfied: distlib<1,>=0.3.7 in /opt/conda/lib/python3.10/site-packages (from virtualenv>=20.24.3->tox>=3.0.0->attributedict->autoawq==0.1.7) (0.3.7)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk->rouge-score>=0.0.4->lm-eval->autoawq==0.1.7) (8.1.7)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets>=2.0.0->lm-eval->autoawq==0.1.7) (2023.3)\n",
      "Using cached transformers-4.35.2-py3-none-any.whl (7.9 MB)\n",
      "Installing collected packages: transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.34.0\n",
      "    Uninstalling transformers-4.34.0:\n",
      "      Successfully uninstalled transformers-4.34.0\n",
      "Successfully installed transformers-4.35.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install einops autoawq==0.1.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd27439c-9ab8-4d6c-bd1f-86d123db46eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!huggingface-cli login --token <MY_HF_TOKEN>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fc830c-3299-47a7-91d1-80c4972a785f",
   "metadata": {},
   "source": [
    "PhoGPT-7B5 QUANTIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3cf4122-95ff-4c70-ad3a-11ac990809cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: transformers\n",
      "Version: 4.35.2\n",
      "Summary: State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow\n",
      "Home-page: https://github.com/huggingface/transformers\n",
      "Author: The Hugging Face team (past and future) with the help of all our contributors (https://github.com/huggingface/transformers/graphs/contributors)\n",
      "Author-email: transformers@huggingface.co\n",
      "License: Apache 2.0 License\n",
      "Location: /opt/conda/lib/python3.10/site-packages\n",
      "Requires: filelock, huggingface-hub, numpy, packaging, pyyaml, regex, requests, safetensors, tokenizers, tqdm\n",
      "Required-by: autoawq, lm-eval\n",
      "---\n",
      "Name: torch\n",
      "Version: 2.1.0\n",
      "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
      "Home-page: https://pytorch.org/\n",
      "Author: PyTorch Team\n",
      "Author-email: packages@pytorch.org\n",
      "License: BSD-3\n",
      "Location: /opt/conda/lib/python3.10/site-packages\n",
      "Requires: filelock, fsspec, jinja2, networkx, sympy, typing-extensions\n",
      "Required-by: accelerate, autoawq, lm-eval, torchaudio, torchelastic, torchvision\n",
      "---\n",
      "Name: autoawq\n",
      "Version: 0.1.7+cu118\n",
      "Summary: AutoAWQ implements the AWQ algorithm for 4-bit quantization with a 2x speedup during inference.\n",
      "Home-page: https://github.com/casper-hansen/AutoAWQ\n",
      "Author: Casper Hansen\n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: /opt/conda/lib/python3.10/site-packages\n",
      "Requires: accelerate, attributedict, lm-eval, protobuf, sentencepiece, tabulate, texttable, tokenizers, toml, torch, torchvision, transformers\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show transformers torch autoawq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "244d36ee-b9d5-45c1-a9fa-3618cf200dda",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/.cache/huggingface/modules/transformers_modules/vinai/PhoGPT-7B5-Instruct/d1a5a418bf01d49e8bf1b5b737b8ef143a33d9fd/configuration_mpt.py:97: UserWarning: alibi is turned on, setting `learned_pos_emb` to `False.`\n",
      "  warnings.warn(f'alibi is turned on, setting `learned_pos_emb` to `False.`')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8be1e45cb9714950bc4c621c5914d5de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 24 files:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/.cache/huggingface/modules/transformers_modules/d1a5a418bf01d49e8bf1b5b737b8ef143a33d9fd/configuration_mpt.py:97: UserWarning: alibi is turned on, setting `learned_pos_emb` to `False.`\n",
      "  warnings.warn(f'alibi is turned on, setting `learned_pos_emb` to `False.`')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b600815eb0bb4d619b36219b122cd8a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "/opt/conda/lib/python3.10/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (7822 > 2048). Running this sequence through the model will result in indexing errors\n",
      "AWQ:   0%|          | 0/32 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "GroupedQueryAttention.forward() got an unexpected keyword argument 'output_attentions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_path, trust_remote_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Quantize\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquant_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquant_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/awq/models/base.py:53\u001b[0m, in \u001b[0;36mBaseAWQForCausalLM.quantize\u001b[0;34m(self, tokenizer, quant_config, calib_data, split, text_column)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquant_config: AwqConfig \u001b[38;5;241m=\u001b[39m AwqConfig\u001b[38;5;241m.\u001b[39mfrom_dict(quant_config)\n\u001b[1;32m     49\u001b[0m quantizer \u001b[38;5;241m=\u001b[39m AwqQuantizer(\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, tokenizer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquant_config\u001b[38;5;241m.\u001b[39mw_bit, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquant_config\u001b[38;5;241m.\u001b[39mq_group_size,\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquant_config\u001b[38;5;241m.\u001b[39mversion, calib_data, split, text_column\n\u001b[1;32m     52\u001b[0m )\n\u001b[0;32m---> 53\u001b[0m \u001b[43mquantizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_quantized \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/awq/quantize/quantizer.py:89\u001b[0m, in \u001b[0;36mAwqQuantizer.quantize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m# [STEP 2]: Compute and apply scale list\u001b[39;00m\n\u001b[1;32m     86\u001b[0m module_config: List[Dict] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mawq_model\u001b[38;5;241m.\u001b[39mget_layers_for_scaling(\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodules[i], input_feat, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule_kwargs\n\u001b[1;32m     88\u001b[0m )\n\u001b[0;32m---> 89\u001b[0m scales_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_search_best_scale(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodules[i], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mlayer) \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m module_config]\n\u001b[1;32m     90\u001b[0m apply_scale(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodules[i], scales_list, input_feat_dict\u001b[38;5;241m=\u001b[39minput_feat)\n\u001b[1;32m     91\u001b[0m scales_list \u001b[38;5;241m=\u001b[39m append_str_prefix(scales_list, get_op_name(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodules[i]) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/awq/quantize/quantizer.py:89\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m# [STEP 2]: Compute and apply scale list\u001b[39;00m\n\u001b[1;32m     86\u001b[0m module_config: List[Dict] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mawq_model\u001b[38;5;241m.\u001b[39mget_layers_for_scaling(\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodules[i], input_feat, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule_kwargs\n\u001b[1;32m     88\u001b[0m )\n\u001b[0;32m---> 89\u001b[0m scales_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_search_best_scale\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodules\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m module_config]\n\u001b[1;32m     90\u001b[0m apply_scale(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodules[i], scales_list, input_feat_dict\u001b[38;5;241m=\u001b[39minput_feat)\n\u001b[1;32m     91\u001b[0m scales_list \u001b[38;5;241m=\u001b[39m append_str_prefix(scales_list, get_op_name(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodules[i]) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/awq/quantize/quantizer.py:160\u001b[0m, in \u001b[0;36mAwqQuantizer._search_best_scale\u001b[0;34m(self, module, prev_op, layers, inp, module2inspect, kwargs)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;66;03m# [STEP 3]: Compute output of module\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 160\u001b[0m     fp16_output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule2inspect\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fp16_output, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    162\u001b[0m         fp16_output \u001b[38;5;241m=\u001b[39m fp16_output[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: GroupedQueryAttention.forward() got an unexpected keyword argument 'output_attentions'"
     ]
    }
   ],
   "source": [
    "from awq import AutoAWQForCausalLM\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_path = 'vinai/PhoGPT-7B5-Instruct'\n",
    "quant_path = 'PhoGPT-7B5-Instruct-AWQ'\n",
    "quant_config = { \"zero_point\": True, \"q_group_size\": 128, \"w_bit\": 4, \"version\": \"GEMM\" }\n",
    "\n",
    "# Load model\n",
    "model = AutoAWQForCausalLM.from_pretrained(model_path, trust_remote_code=True,device_map={\"\": \"cpu\"}, **{\"low_cpu_mem_usage\": True})\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
    "\n",
    "# Quantize\n",
    "model.quantize(tokenizer, quant_config=quant_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c59376-44e7-44c6-8f51-9fd481f616ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save quantized model\n",
    "model.save_quantized(quant_path)\n",
    "tokenizer.save_pretrained(quant_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a922a31-bdb9-427a-88e9-3e1b02192e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"PhoGPT-7B5-Instruct-AWQ\"\n",
    "HUGGING_FACE_USER_NAME=\"phatjk\"\n",
    "model.push_to_hub(f\"{HUGGING_FACE_USER_NAME}/{model_name}\", use_auth_token=True)\n",
    "tokenizer.push_to_hub(f\"{HUGGING_FACE_USER_NAME}/{model_name}\", use_auth_token=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ee8786-e88b-4faf-acae-0d1f3d745471",
   "metadata": {},
   "source": [
    "vietcuna-7b-v3 QUANTIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d6c500f-24ab-4041-90c6-9dd5fb4e6ff0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e37b9922d97f4f61a7f7eb05a289923e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 8 files:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f105d590a22b4569af7f51449d2aafbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "/opt/conda/lib/python3.10/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n",
      "AWQ: 100%|██████████| 30/30 [19:33<00:00, 39.12s/it]\n"
     ]
    }
   ],
   "source": [
    "from awq import AutoAWQForCausalLM\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_path = 'vilm/vietcuna-7b-v3'\n",
    "quant_path = 'vietcuna-7b-v3-AWQ'\n",
    "quant_config = { \"zero_point\": True, \"q_group_size\": 128, \"w_bit\": 4, \"version\": \"GEMM\" }\n",
    "\n",
    "# Load model\n",
    "model = AutoAWQForCausalLM.from_pretrained(model_path,device_map={\"\": \"cpu\"}, trust_remote_code=True, **{\"low_cpu_mem_usage\": True})\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
    "\n",
    "# Quantize\n",
    "model.quantize(tokenizer, quant_config=quant_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e1dcf7a-0ee1-45eb-90e6-cc0f1e4442e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:`quant_config.json` is being deprecated in the future in favor of quantization_config in config.json.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('vietcuna-7b-v3-AWQ/tokenizer_config.json',\n",
       " 'vietcuna-7b-v3-AWQ/special_tokens_map.json',\n",
       " 'vietcuna-7b-v3-AWQ/tokenizer.json')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save quantized model\n",
    "model.save_quantized(quant_path)\n",
    "tokenizer.save_pretrained(quant_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a813dd6b-565f-49ac-9ed4-cd6fe36285af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1d4c52185864a61ba8f36f7941030fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/14.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6af70bba5e0d45afbc8c5df24a4d293f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/7.25G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04440febc7ab4c17a51e3321298d462b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/phatjk/vietcuna-7b-v3-AWQ/tree/main/'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import HfApi\n",
    "api = HfApi()\n",
    "model_name = \"vietcuna-7b-v3-AWQ\"\n",
    "HUGGING_FACE_USER_NAME=\"phatjk\"\n",
    "api.upload_folder(\n",
    "    folder_path=\"vietcuna-7b-v3-AWQ\",\n",
    "    repo_id=HUGGING_FACE_USER_NAME+\"/\"+model_name,\n",
    "    repo_type=\"model\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
